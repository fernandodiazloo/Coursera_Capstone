{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I - reading postal codes (scroll down for tasks 2 and 3)\n",
    "\n",
    "\n",
    "Import all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the page into parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\")\n",
    "soup = BeautifulSoup (r.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse page into a dictionary where each postal code is represented with one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NA  =\"Not assigned\" # A constant for \"Not assigned marker\"\n",
    "\n",
    "pc_dict = dict() # A dictionary for postal codes. One postal code - one entry in the dict.\n",
    "\n",
    "rows = soup.table.find_all(\"tr\") # The data are in the first table. Let's read line by line\n",
    "for r in rows:\n",
    "    tds = r.find_all(\"td\")\n",
    "    if len(tds) > 0:                     # ignore headings\n",
    "        code = tds[0].text.strip()       # remove extra characters (there are some!)\n",
    "        borough = tds[1].text.strip()\n",
    "        neigh = tds[2].text.strip()\n",
    "        \n",
    "        if (borough != NA):              # Ignore lines where borough is unassigned\n",
    "            if (neigh == NA):            # Fill in unassigned neighbourhood\n",
    "                neigh = borough\n",
    "            if code in pc_dict:          # Did we see this postal code before?\n",
    "                line = pc_dict[code]     # ... yes - then just add another neighbourhood\n",
    "                line[2] += \",\" + neigh\n",
    "            else:                        # ... no - create a new entry\n",
    "                pc_dict[code] = [code, borough, neigh]\n",
    "#print(pc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform dictionary into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postalCodes = pd.DataFrame(list(pc_dict.values()), columns = ['PostalCode', 'Borough', 'Neighborhood'])\n",
    "postalCodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postalCodes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Get coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to get coordinates for each postal code.\n",
    "\n",
    "First, let's try geocoder as in the assignment description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geocoder # import geocoder\n",
    "\n",
    "# initialize your variable to None\n",
    "lat_lng_coords = None\n",
    "\n",
    "# loop until you get the coordinates\n",
    "inf_loop_braker = 0\n",
    "while(lat_lng_coords is None and inf_loop_braker < 5):\n",
    "    g = geocoder.google('{}, Toronto, Ontario'.format(\"M5G\"))\n",
    "    lat_lng_coords = g.latlng\n",
    "    print (\"Iteration: {}, coordinates: {}\".format(inf_loop_braker, lat_lng_coords))\n",
    "    inf_loop_braker += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No matter gow many time I try and what address I use it is always None\n",
    "\n",
    "Then, let's try Nominatim as in the lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"ny_explorer\")\n",
    "def test_address(address):\n",
    "    location = geolocator.geocode(address)\n",
    "    if location is None:\n",
    "        print (\"Location '{}' not found\".format(address))\n",
    "    else:\n",
    "        print (\"Coordinates for '{}': {}, {}\".format(address, location.latitude, location.longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_address(\"M5A, Toronto, Ontario\")\n",
    "test_address(\"M5A, Toronto, Ontario, Canada\")\n",
    "test_address(\"M5G, Toronto, Ontario\")\n",
    "test_address(\"M5G, Toronto, Ontario, Canada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filled = 0\n",
    "for i in postalCodes.index:\n",
    "    address = \"{}, Toronto, Ontario\".format(postalCodes.PostalCode[i])\n",
    "    location = geolocator.geocode(address)\n",
    "    if not location is None:\n",
    "        n_filled += 1\n",
    "        \n",
    "print (\"Number of found zip codes: {}\".format(n_filled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some zip codes are recogined, but only minor part. And even for those recognized coordinates are different than in \"Geospacial_coordinates.csv\".\n",
    "\n",
    "Thus for consistency let's use Geospacial_coordinates.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = pd.read_csv(\"Geospatial_Coordinates.csv\")\n",
    "coordinates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postalCodes = postalCodes.merge(coordinates, left_on=\"PostalCode\", right_on=\"Postal Code\").drop(columns=[\"Postal Code\"])\n",
    "postalCodes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3, explore, visualize and cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start with simply showing all the neighborhoods on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# Create a map centered at Toronto\n",
    "location = geolocator.geocode(\"Toronto, Canada\")\n",
    "map_toronto = folium.Map(location=[location.latitude, location.longitude], zoom_start=11)\n",
    "\n",
    "# Select only boroughs with \"Toronto\" in the name\n",
    "torontoCodes = postalCodes[postalCodes.Borough.apply(lambda x: \"Toronto\" in x)]\n",
    "\n",
    "# Add markers for each Neighborhood (or more precisely - for each postal code)\n",
    "for lat, lng, borough, neighborhood in zip(torontoCodes['Latitude'], torontoCodes['Longitude'], torontoCodes['Borough'], torontoCodes['Neighborhood']):\n",
    "    label = '{}, {}'.format(neighborhood, borough)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_toronto)  \n",
    "    \n",
    "map_toronto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Venues data\n",
    "\n",
    "Now let get venues from FourSquare. **In order to run further cells you need to  type in your credentials in the below box or create a file with Foursquare ID and secret.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'REPLACE WITH YOUR ID OR CREATE A FILE FS_cred.txt' # your Foursquare ID\n",
    "CLIENT_SECRET = 'REPLACE WITH YOUR SECRET OR CREATE A FILE FS_cred.txt' # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "\n",
    "\n",
    "try:\n",
    "    filename = \"FS_cred.txt\" \n",
    "    # This block will read \n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        CLIENT_ID = lines[0].strip()\n",
    "        CLIENT_SECRET = lines[1].strip()\n",
    "        print (\"Foursquare credentials read from '{}'\".format(filename))\n",
    "except:\n",
    "    print (\"Could not read '{}'\".format(filename))\n",
    "\n",
    "print('Your credentails:')\n",
    "print('CLIENT_ID: ' + CLIENT_ID)\n",
    "print('CLIENT_SECRET:' + CLIENT_SECRET)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get venues around \"zipcode center\" location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT = 100\n",
    "def getNearbyVenues(codes, names, latitudes, longitudes, radius=500):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for code, name, lat, lng in zip(codes, names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            code,\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Zipcode', \n",
    "                  'Neighborhood',           \n",
    "                  'Zipcode Latitude', \n",
    "                  'Zipcode Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_venues = getNearbyVenues(  codes=torontoCodes['PostalCode'],\n",
    "                                   names=torontoCodes['Neighborhood'],\n",
    "                                   latitudes=torontoCodes['Latitude'],\n",
    "                                   longitudes=torontoCodes['Longitude']\n",
    "                                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(toronto_venues.shape)\n",
    "toronto_venues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases number of venues is below the limit of 100. Several neighborhood have less than 10 venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_venue_counts = toronto_venues.groupby('Neighborhood').count().reset_index()[[\"Neighborhood\", \"Venue\"]]\n",
    "toronto_venue_counts.columns = [\"Neighborhood\", \"N of Venues\"]\n",
    "toronto_venue_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} uniques categories.'.format(len(toronto_venues['Venue Category'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells neighborhood will be clustered by ratio of various venue categories. \n",
    "\n",
    "Convert categorical variable into one-hot encoding and then to ratio of each category within a neighborhood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "toronto_onehot = pd.get_dummies(toronto_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "toronto_onehot['Neighborhood'] = toronto_venues['Neighborhood'] \n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [toronto_onehot.columns[-1]] + list(toronto_onehot.columns[:-1])\n",
    "toronto_onehot = toronto_onehot[fixed_columns]\n",
    "\n",
    "toronto_grouped = toronto_onehot.groupby('Neighborhood').mean().reset_index()\n",
    "toronto_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe that shows 10 most common categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]\n",
    "\n",
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Neighborhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "neighborhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "neighborhoods_venues_sorted['Neighborhood'] = toronto_grouped['Neighborhood']\n",
    "\n",
    "for ind in np.arange(toronto_grouped.shape[0]):\n",
    "    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(toronto_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "neighborhoods_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kclusters = 5\n",
    "\n",
    "toronto_grouped_clustering = toronto_grouped.drop('Neighborhood', 1)\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(toronto_grouped_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clustering labels\n",
    "neighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n",
    "\n",
    "toronto_merged = torontoCodes\n",
    "\n",
    "# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\n",
    "toronto_merged = toronto_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n",
    "toronto_merged = toronto_merged.join(toronto_venue_counts.set_index('Neighborhood'), on='Neighborhood')\n",
    "\n",
    "toronto_merged.head() # check the last columns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "# create map\n",
    "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(toronto_merged['Latitude'], toronto_merged['Longitude'], toronto_merged['Neighborhood'], toronto_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see on the map, clustering did not produce any significant grouping. Most of points went to cluster 0. Other clusters are formed from the neighborhoods witrh only 1-4 venues. Changing target number of clusters does not help.\n",
    "\n",
    "A hypothesis that could be tested as a next step: \n",
    "* group categories into some super-categories, such as drink/food, shops, parks, other\n",
    "* cluster by number of national cuisine restaurants\n",
    "* number or venues may be one best single criteria for clustering\n",
    "\n",
    "Choice of hypothesis to test next would depend on task context (if it was real world task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_merged.groupby(\"Cluster Labels\").count().reset_index()[[\"Cluster Labels\", \"PostalCode\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_merged.loc[toronto_merged['Cluster Labels'] != 0, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
